services:
  # PostgreSQL - Source Database
  postgres:
    image: postgres:${POSTGRES_VERSION}
    container_name: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    command: >
      postgres
      -c wal_level=logical
      -c max_wal_senders=4
      -c max_replication_slots=4
      -c listen_addresses='*'
    networks:
      - el-pipeline-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Adminer - PostgreSQL UI
  adminer:
    image: adminer:latest
    container_name: adminer
    ports:
      - "8081:8080"
    networks:
      - el-pipeline-network
    depends_on:
      - postgres

  # Apache Kafka (KRaft mode - no Zookeeper)
  kafka:
    image: apache/kafka:${KAFKA_VERSION}
    container_name: kafka
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: ${KAFKA_CLUSTER_ID}
    ports:
      - "9092:9092"
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - el-pipeline-network
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s

  # Confluent Schema Registry
  schema-registry:
    image: confluentinc/cp-schema-registry:${SCHEMA_REGISTRY_VERSION}
    container_name: schema-registry
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:9092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: 1
      SCHEMA_REGISTRY_DEBUG: 'true'
    ports:
      - "8085:8081"
    networks:
      - el-pipeline-network
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Schema Registry UI
  schema-registry-ui:
    image: landoop/schema-registry-ui:latest
    container_name: schema-registry-ui
    environment:
      SCHEMAREGISTRY_URL: http://schema-registry:8081
      PROXY: 'true'
    ports:
      - "8086:8000"
    networks:
      - el-pipeline-network
    depends_on:
      - schema-registry

  # Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    environment:
      KAFKA_CLUSTERS_0_NAME: kafka-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
      DYNAMIC_CONFIG_ENABLED: 'true'
    ports:
      - "8082:8080"
    networks:
      - el-pipeline-network
    depends_on:
      - kafka
      - schema-registry

  # Kafka Connect with Debezium
  kafka-connect:
    build:
      context: ./kafka-connect
      dockerfile: Dockerfile
    image: kafka-connect-avro:latest
    container_name: kafka-connect
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: debezium-cluster
      CONFIG_STORAGE_TOPIC: debezium_connect_configs
      OFFSET_STORAGE_TOPIC: debezium_connect_offsets
      STATUS_STORAGE_TOPIC: debezium_connect_status
      CONFIG_STORAGE_REPLICATION_FACTOR: 1
      OFFSET_STORAGE_REPLICATION_FACTOR: 1
      STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_PARTITIONS: 25
      CONNECT_STATUS_STORAGE_PARTITIONS: 5
    ports:
      - "8083:8083"
    networks:
      - el-pipeline-network
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8083/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MinIO - S3-compatible Object Storage
  minio:
    image: minio/minio:latest
    container_name: minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data
    command: server /data --console-address ":9001"
    networks:
      - el-pipeline-network
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MinIO Init - Create buckets
  minio-init:
    image: minio/mc:latest
    container_name: minio-init
    networks:
      - el-pipeline-network
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set minio http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD};
      mc mb minio/${MINIO_BUCKET} --ignore-existing;
      exit 0;
      "

  # JupyterLab - Data Analysis Environment (Spark 4.0.1)
  jupyter:
    build:
      context: ./jupyter
      dockerfile: Dockerfile
    container_name: jupyter
    environment:
      JUPYTER_TOKEN: ${JUPYTER_TOKEN}
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
    networks:
      - el-pipeline-network
    depends_on:
      - minio

  # Spark Master
  spark-master:
    image: apache/spark:${SPARK_VERSION}-python3
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./spark/conf:/opt/spark/conf
      - ./spark/jobs:/opt/spark/jobs
      - spark-checkpoints:/opt/spark/checkpoints
    networks:
      - el-pipeline-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Spark Worker
  spark-worker:
    image: apache/spark:${SPARK_VERSION}-python3
    container_name: spark-worker
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://${SPARK_MASTER_HOST}:${SPARK_MASTER_PORT}
    environment:
      - SPARK_WORKER_CORES=${SPARK_WORKER_CORES}
      - SPARK_WORKER_MEMORY=${SPARK_WORKER_MEMORY}
    ports:
      - "8091:8081"
    volumes:
      - ./spark/conf:/opt/spark/conf
      - ./spark/jobs:/opt/spark/jobs
      - spark-checkpoints:/opt/spark/checkpoints
    networks:
      - el-pipeline-network
    depends_on:
      spark-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
      minio:
        condition: service_healthy

networks:
  el-pipeline-network:
    driver: bridge
    name: el-pipeline-network

volumes:
  postgres-data:
    name: postgres-data
  kafka-data:
    name: kafka-data
  minio-data:
    name: minio-data
  spark-checkpoints:
    name: spark-checkpoints
